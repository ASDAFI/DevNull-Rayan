{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e122267-386e-4760-9e2c-6b59c9abd21b",
   "metadata": {},
   "source": [
    "# Logging utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611106c-9e35-42f1-8a96-271a66f2e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "\n",
    "! rm -rf logs\n",
    "\n",
    "log_dir = 'logs'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "LOGGER = logging.getLogger('notebook')\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "\n",
    "log_file_path = os.path.join(log_dir, 'run.log')\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "LOGGER.addHandler(file_handler)\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(formatter)\n",
    "LOGGER.addHandler(console_handler)\n",
    "\n",
    "logging_redirect_tqdm()\n",
    "\n",
    "LOGGER.debug(\"This is a debug message\")\n",
    "LOGGER.info(\"This is an info message\")\n",
    "LOGGER.warning(\"This is a warning message\")\n",
    "LOGGER.error(\"This is an error message\")\n",
    "LOGGER.critical(\"This is a critical message\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cab99-a097-47ba-a897-1e48025ba760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timeit(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        LOGGER.info(f\"Function '{func.__name__}' executed in {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d82f8dc-fb24-47f2-87aa-715f01d788cc",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0434c-e5a7-4e0c-a83b-f56493ab0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install huggingface_hub\n",
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55f632-3b59-411c-82fa-d52e8fcad8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "import sys\n",
    "\n",
    "dataset_id=\"RayanAi/Main_teeth_dataset\"\n",
    "local_dataset_dir = \"./Main_teeth_dataset\"  \n",
    "\n",
    "os.makedirs(local_dataset_dir, exist_ok=True)\n",
    "\n",
    "with open(os.devnull, 'w') as fnull:\n",
    "    original_stdout = sys.stdout\n",
    "    try:\n",
    "        sys.stdout = fnull\n",
    "        snapshot_download(repo_id=dataset_id, local_dir=local_dataset_dir, repo_type=\"dataset\")\n",
    "    finally:\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "LOGGER.info(\"Dataset downloaded completely.\")\n",
    "\n",
    "total_size = 0\n",
    "for dirpath, dirnames, filenames in os.walk(local_dataset_dir):\n",
    "    for f in filenames:\n",
    "        fp = os.path.join(dirpath, f)\n",
    "        total_size += os.path.getsize(fp)\n",
    "\n",
    "LOGGER.info(f\"Total size of downloaded files: {total_size / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "dataset_abs_path = os.path.abspath(local_dataset_dir)\n",
    "LOGGER.info(f\"Dataset has been saved at: [{dataset_abs_path}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d97705-e1e7-475b-bd0f-ce92ab32c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q ./Main_teeth_dataset/Main_teeth_dataset.zip -d ./Main_teeth_dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff9ba5-bde7-435d-ae56-a52d311b9186",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85982487-9057-4f7e-b980-c8608c8c1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb2b32-e2b3-418a-ae0f-d990a16e3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        LOGGER.error(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6efdd-2368-40e2-8d9b-ed874aeaf1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TeethDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.loaded_data: List[Tuple[np.ndarray, np.ndarray]] = []\n",
    "        self.X: List[torch.Tensor] = []\n",
    "        self.y: List[torch.Tensor] = []\n",
    "\n",
    "    def load(self, data: List[Tuple[str, str]]):\n",
    "        for image_path, label_path in data:\n",
    "            image = np.array(load_image(image_path))  # Should return a numpy array\n",
    "            label = np.array(load_image(label_path))  # Should return a numpy array\n",
    "            self.loaded_data.append((image, label))\n",
    "\n",
    "    def augment(self, generation_per_sample: int, augmentation: A.Compose):\n",
    "        LOGGER.info(\"Augmenting data ...\")\n",
    "        augmented_data = []\n",
    "        for image, label in tqdm(self.loaded_data):\n",
    "            for _ in range(generation_per_sample):\n",
    "                augmented = augmentation(image=image, mask=label)\n",
    "                augmented_image = augmented['image']\n",
    "                augmented_label = augmented['mask']\n",
    "                augmented_data.append((augmented_image, augmented_label))\n",
    "        self.loaded_data.extend(augmented_data)\n",
    "        random.seed(68)\n",
    "        random.shuffle(self.loaded_data)\n",
    "\n",
    "    def transform(self, transformation: A.Compose):\n",
    "        for image, label in self.loaded_data:\n",
    "            transformed = transformation(image=image, mask=label)\n",
    "            transformed_image = transformed['image']\n",
    "            transformed_label = transformed['mask']\n",
    "\n",
    "            binary_mask = transformed_label.unsqueeze(2)>0\n",
    "            binary_mask = binary_mask.permute(2, 0, 1).float()\n",
    "            \n",
    "            \n",
    "            self.X.append(transformed_image)\n",
    "            self.y.append(binary_mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48d82b-772d-4e24-a322-a26cc7061bfc",
   "metadata": {},
   "source": [
    "# Load images path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72f124-7c7b-4439-a31b-52ccc9fc2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "labels_root = os.path.join(local_dataset_dir, 'labels')\n",
    "images_root = os.path.join(local_dataset_dir, 'images')\n",
    "\n",
    "\n",
    "images_path = glob.glob(os.path.join(images_root, '*.png'))\n",
    "labels_path = glob.glob(os.path.join(labels_root, '*.png'))\n",
    "\n",
    "\n",
    "len(labels_path), len(images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a681c924-18ab-410c-a50e-676892cb75d9",
   "metadata": {},
   "source": [
    "# Remove noisy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2511b-c2d5-4eb7-9329-e3289b49dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_entropy(image):\n",
    "    image_array = np.array(image)\n",
    "    hist, _ = np.histogram(image_array, bins=256, range=(0, 256), density=True)\n",
    "    entropy = -np.sum(hist * np.log2(hist + 1e-7))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def get_noisy_images(images_path: List[str], threshold: float):\n",
    "    noisy_images = []\n",
    "    for file_path in images_path:\n",
    "        img = load_image(file_path)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "    \n",
    "        img = img.convert(\"L\")\n",
    "    \n",
    "        entropy = calculate_entropy(img)\n",
    "    \n",
    "        if entropy >= threshold:\n",
    "            noisy_images.append(file_path)\n",
    "            \n",
    "    return noisy_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc14274-8593-486a-963a-86d29f5156d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER.info(len(images_path), len(labels_path))\n",
    "\n",
    "random.shuffle(labels_path)\n",
    "\n",
    "noisy_images = get_noisy_images(labels_path, 0.2)\n",
    "LOGGER.info(len(noisy_images))\n",
    "labels_path = [label_path for label_path in labels_path\n",
    "               if label_path not in noisy_images]\n",
    "images_path = [os.path.join(images_root, os.path.basename(file_path)) for file_path in labels_path] \n",
    "\n",
    "LOGGER.info(len(images_path), len(labels_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55617959-1b41-4984-a4e0-4521a3190e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    LOGGER.info(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    LOGGER.info(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LOGGER.info(f'Device is {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094640f6-168a-4419-8ebb-9e111b158678",
   "metadata": {},
   "source": [
    "# Exploration on Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd537b37-d552-4357-94e0-801512aacc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_image(img):\n",
    "    if img.dtype != np.uint8:\n",
    "        img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def prepare_label(lbl):\n",
    "    lbl = (lbl > 0).astype(np.uint8) * 255\n",
    "    return lbl\n",
    "\n",
    "\n",
    "def plot_augmentations(original_image, augmented_image, original_label, augmented_label):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "    axs[0, 0].imshow(original_image, cmap='gray')\n",
    "    axs[0, 0].set_title('Original Image')\n",
    "    axs[0, 0].axis('off')\n",
    "\n",
    "    axs[0, 1].imshow(augmented_image, cmap='gray')\n",
    "    axs[0, 1].set_title('Augmented Image')\n",
    "    axs[0, 1].axis('off')\n",
    "\n",
    "    axs[1, 0].imshow(original_label, cmap='gray')\n",
    "    axs[1, 0].set_title('Original Label')\n",
    "    axs[1, 0].axis('off')\n",
    "\n",
    "    axs[1, 1].imshow(augmented_label, cmap='gray')\n",
    "    axs[1, 1].set_title('Augmented Label')\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "AUGMENTATION_SAMPLE = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5, border_mode=0),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.0625, scale_limit=0.1, rotate_limit=0,\n",
    "        p=0.5, border_mode=0\n",
    "    ),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.GaussianBlur(blur_limit=(3, 7)),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0)),\n",
    "    ], p=0.5),\n",
    "],\n",
    "additional_targets={'mask': 'mask'})\n",
    "\n",
    "\n",
    "\n",
    "image = np.array(load_image(images_path[0]))\n",
    "label = np.array(load_image(labels_path[0]))\n",
    "\n",
    "\n",
    "\n",
    "augmented = AUGMENTATION_SAMPLE(image=image, mask=label)\n",
    "augmented_image = augmented['image']\n",
    "augmented_label = augmented['mask']\n",
    "\n",
    "\n",
    "image_plot = prepare_image(image)\n",
    "augmented_image_plot = prepare_image(augmented_image)\n",
    "label_plot = prepare_label(label)\n",
    "augmented_label_plot = prepare_label(augmented_label)    \n",
    "\n",
    "plot_augmentations(image_plot, augmented_image_plot, label_plot, augmented_label_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e37c84-c244-4469-94dc-519969ccf1fa",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a944d61-3ba0-4662-a731-0197a24178cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def generate_random_string(length=8, use_digits=True, use_lowercase=True, use_uppercase=True, use_special=False):\n",
    "    char_pool = ''\n",
    "    if use_digits:\n",
    "        char_pool += string.digits\n",
    "    if use_lowercase:\n",
    "        char_pool += string.ascii_lowercase\n",
    "    if use_uppercase:\n",
    "        char_pool += string.ascii_uppercase\n",
    "    if use_special:\n",
    "        char_pool += string.punctuation\n",
    "\n",
    "    if not char_pool:\n",
    "        raise ValueError(\"At least one character type must be enabled.\")\n",
    "\n",
    "    return ''.join(random.choice(char_pool) for _ in range(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7fb5a-8c4e-4104-9d19-76ecef791c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dice_score(preds, targets, epsilon=1e-6):\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = (preds > 0.5).float()\n",
    "    intersection = (preds * targets).sum(dim=(1, 2, 3))\n",
    "    dice = (2. * intersection + epsilon) / (preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3)) + epsilon)\n",
    "    return dice.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e6498-ed7b-4565-bc21-d52e7b44134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "@timeit\n",
    "def train_epoch(model: torch.nn.Module, train_loader: DataLoader, optimizer, criterion) -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    total_dice_score = 0.0\n",
    "\n",
    "    for inputs, masks in tqdm(train_loader, desc=\"Training\"):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * inputs.size(0)\n",
    "        dice = dice_score(outputs, masks)\n",
    "        total_dice_score += dice * inputs.size(0)\n",
    "\n",
    "        del inputs, masks, outputs, loss, dice\n",
    "\n",
    "    epoch_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "    epoch_dice_score = total_dice_score / len(train_loader.dataset)\n",
    "\n",
    "    return epoch_train_loss, epoch_dice_score\n",
    "\n",
    "@timeit\n",
    "def val_epoch(model: torch.nn.Module, val_loader: DataLoader, criterion) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    total_dice_score = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in tqdm(val_loader, desc=\"Validation\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_val_loss += loss.item() * inputs.size(0)\n",
    "            dice = dice_score(outputs, masks)\n",
    "            total_dice_score += dice * inputs.size(0)\n",
    "\n",
    "            del inputs, masks, outputs, loss, dice\n",
    "\n",
    "    epoch_val_loss = total_val_loss / len(val_loader.dataset)\n",
    "    epoch_dice_score = total_dice_score / len(val_loader.dataset)\n",
    "\n",
    "    return epoch_val_loss, epoch_dice_score\n",
    "\n",
    "@timeit\n",
    "def test_model(model: torch.nn.Module, test_loader: DataLoader, criterion) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_test_loss = 0.0\n",
    "    total_dice_score = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_test_loss += loss.item() * inputs.size(0)\n",
    "            dice = dice_score(outputs, masks)\n",
    "            total_dice_score += dice * inputs.size(0)\n",
    "\n",
    "            del inputs, masks, outputs, loss, dice\n",
    "\n",
    "    epoch_test_loss = total_test_loss / len(test_loader.dataset)\n",
    "    epoch_test_dice_score = total_dice_score / len(test_loader.dataset)\n",
    "\n",
    "    return epoch_test_loss, epoch_test_dice_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c71c9e-b7ab-41f1-a478-c2a39335c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@timeit\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataset: torch.utils.data.Dataset,\n",
    "    val_dataset: torch.utils.data.Dataset,\n",
    "    test_dataset: torch.utils.data.Dataset,\n",
    "    stable_epochs_count: int,\n",
    "    stable_dice_score_distance: float,\n",
    "    best_models_dir: str,\n",
    "    stable_models_dir: str,\n",
    "    epochs: int = 100\n",
    ") -> Tuple[list, list, list, list, str, str, float, float, float, float]:\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()#nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_dice_scores = []\n",
    "    val_dice_scores = []\n",
    "\n",
    "    best_val_dice_score = 0\n",
    "    best_stable_dice_score = 0\n",
    "\n",
    "    best_model_path = \"\"\n",
    "    best_stable_model_path = \"\"\n",
    "\n",
    "    models_history_in_memory = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_train_loss, train_dice = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_dice_scores.append(train_dice)\n",
    "\n",
    "        epoch_val_loss, val_dice = val_epoch(model, val_loader, criterion)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_dice_scores.append(val_dice)\n",
    "\n",
    "        models_history_in_memory.append(copy.deepcopy(model))\n",
    "        if len(models_history_in_memory) > stable_epochs_count:\n",
    "            models_history_in_memory.pop(0)\n",
    "\n",
    "        if val_dice > best_val_dice_score:\n",
    "            best_val_dice_score = val_dice\n",
    "            model_path = os.path.join(\n",
    "                best_models_dir,\n",
    "                f'dice_{round(val_dice, 4)}_epoch_{epoch+1}_{generate_random_string(3)}.pth'\n",
    "            )\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            best_model_path = model_path\n",
    "            LOGGER.info(f'Model saved: {model_path}')\n",
    "\n",
    "        if epoch >= 50 and len(val_dice_scores) >= stable_epochs_count:\n",
    "            recent_dice = val_dice_scores[-stable_epochs_count:]\n",
    "            max_diff = max(recent_dice) - min(recent_dice)\n",
    "            if max_diff <= stable_dice_score_distance:\n",
    "                best_idx = recent_dice.index(max(recent_dice))\n",
    "                stable_model = copy.deepcopy(models_history_in_memory[best_idx])\n",
    "                stable_dice = recent_dice[best_idx]\n",
    "                stable_model_path = os.path.join(\n",
    "                    stable_models_dir,\n",
    "                    f'stable_dice_{round(stable_dice, 4)}_epoch_{epoch+1}_{generate_random_string(3)}.pth'\n",
    "                )\n",
    "                torch.save(stable_model.state_dict(), stable_model_path)\n",
    "                best_stable_dice_score = max(best_stable_dice_score, stable_dice)\n",
    "                best_stable_model_path = stable_model_path\n",
    "                LOGGER.info(f'Stable model saved: {stable_model_path}')\n",
    "\n",
    "        LOGGER.info(\n",
    "            f'Epoch {epoch+1}/{epochs} | '\n",
    "            f'Train Loss: {epoch_train_loss:.4f} | Train Dice: {train_dice:.4f} | '\n",
    "            f'Val Loss: {epoch_val_loss:.4f} | Val Dice: {val_dice:.4f}'\n",
    "        )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    best_model = copy.deepcopy(model)\n",
    "    if best_model_path:\n",
    "        best_model.load_state_dict(torch.load(best_model_path))\n",
    "    best_model = best_model.to(DEVICE)\n",
    "    best_model_test_loss, best_model_test_dice_score = test_model(best_model, test_loader, criterion)\n",
    "\n",
    "    if best_stable_model_path:\n",
    "        stable_model = copy.deepcopy(model)\n",
    "        stable_model.load_state_dict(torch.load(best_stable_model_path))\n",
    "        stable_model = stable_model.to(DEVICE)\n",
    "        stable_model_test_loss, stable_model_test_dice_score = test_model(stable_model, test_loader, criterion)\n",
    "    else:\n",
    "        stable_model_test_loss, stable_model_test_dice_score = None, None\n",
    "\n",
    "    return (\n",
    "        train_losses,\n",
    "        train_dice_scores,\n",
    "        val_losses,\n",
    "        val_dice_scores,\n",
    "        best_model_path,\n",
    "        best_stable_model_path,\n",
    "        best_model_test_loss,\n",
    "        best_model_test_dice_score,\n",
    "        stable_model_test_loss,\n",
    "        stable_model_test_dice_score\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e64482-8e88-4d56-8507-438f1d09884f",
   "metadata": {},
   "source": [
    "# Plot utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0d142-3b21-46c7-b6e7-36f8f86fc2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(train_metric, val_metric, save_path, metric_name=\"Loss\", color_train='b', color_val='r'):\n",
    "    epochs = range(1, len(train_metric) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_metric, color=color_train, label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, val_metric, color=color_val, label=f'Validation {metric_name}')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'Training and Validation {metric_name} Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc00f5-3a34-4719-9de3-f5d959ecf505",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f751cf-3b3b-4350-9055-3393b8ff095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "TRAIN_TRANSFORMATION =  A.Compose([\n",
    "    A.Normalize(mean=(0.485,), std=(0.229,), max_pixel_value=255.0),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "VALIDATION_TRANSFORMATION =  A.Compose([\n",
    "    A.Normalize(mean=(0.485,), std=(0.229,), max_pixel_value=255.0),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "TEST_TRANSFORMATION =  A.Compose([\n",
    "    A.Normalize(mean=(0.485,), std=(0.229,), max_pixel_value=255.0),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae145fa0-1efd-4748-bf58-19c8a7e65fed",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4cda2e-b52f-4284-984a-ebbd3336169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_AUGMENTATION = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5, border_mode=0),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.0625, scale_limit=0.1, rotate_limit=0,\n",
    "        p=0.5, border_mode=0\n",
    "    ),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.GaussianBlur(blur_limit=(3, 7)),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0)),\n",
    "    ], p=0.5),\n",
    "],\n",
    "additional_targets={'mask': 'mask'})\n",
    "\n",
    "VALIDATION_AUGMENTATION = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5, border_mode=0),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.0625, scale_limit=0.1, rotate_limit=0,\n",
    "        p=0.5, border_mode=0\n",
    "    ),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.GaussianBlur(blur_limit=(3, 7)),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0)),\n",
    "    ], p=0.5),\n",
    "],\n",
    "additional_targets={'mask': 'mask'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c48cc-9bec-4bc4-afbb-77db530d0817",
   "metadata": {},
   "source": [
    "# Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13399e-e847-46c7-a9b8-0e3770a38641",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TeethDataset()\n",
    "train_dataset.load(zip(images_path[:330], labels_path[:330]))\n",
    "train_dataset.augment(15, TRAIN_AUGMENTATION)\n",
    "train_dataset.transform(TRAIN_TRANSFORMATION)\n",
    "\n",
    "val_dataset = TeethDataset()\n",
    "val_dataset.load(zip(images_path[330:360], labels_path[330:360]))\n",
    "val_dataset.augment(5, VALIDATION_AUGMENTATION)\n",
    "val_dataset.transform(VALIDATION_TRANSFORMATION)\n",
    "\n",
    "test_dataset = TeethDataset()\n",
    "test_dataset.load(zip(images_path[360:], labels_path[360:]))\n",
    "test_dataset.transform(TEST_TRANSFORMATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977adef4-717f-4673-a06f-64b6e59e5b71",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f88577-33cd-47f0-8ef9-ee09abe28f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / (1024 ** 2)\n",
    "    return size_all_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98720b85-29bf-46f4-a33a-3f6243d223e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),  \n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class HeavyUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HeavyUnet, self).__init__()\n",
    "        self.inc = DoubleConv(1, 64)     \n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(64, 128)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(128, 256)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(256, 512)\n",
    "        )\n",
    "        self.down4 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(512, 1024)\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.conv_up1 = DoubleConv(1024, 512)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.conv_up2 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv_up3 = DoubleConv(256, 128)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv_up4 = DoubleConv(128, 64)\n",
    "\n",
    "        # Output layer\n",
    "        self.outc = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    #######DO NOT CHANGE THIS PART########\n",
    "    def init(self, path=\"model.pth\"):\n",
    "        self.load_state_dict(torch.load(path, weights_only=True))\n",
    "    ######################################\n",
    "    def save(self, path: str):\n",
    "        torch.save(copy.deepcopy(self.state_dict()), path)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        x1 = self.inc(x)       \n",
    "        x2 = self.down1(x1)   \n",
    "        x3 = self.down2(x2)    \n",
    "        x4 = self.down3(x3)    \n",
    "        x5 = self.down4(x4) \n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x5)      \n",
    "        x = torch.cat([x, x4], dim=1) \n",
    "        x = self.conv_up1(x)  \n",
    "\n",
    "        x = self.up2(x)    \n",
    "        x = torch.cat([x, x3], dim=1)  \n",
    "        x = self.conv_up2(x)   \n",
    "\n",
    "        x = self.up3(x)        \n",
    "        x = torch.cat([x, x2], dim=1)  \n",
    "        x = self.conv_up3(x) \n",
    "\n",
    "        x = self.up4(x)        \n",
    "        x = torch.cat([x, x1], dim=1) \n",
    "        x = self.conv_up4(x)   \n",
    "\n",
    "        mask = self.outc(x)  \n",
    "        return mask\n",
    "\n",
    "get_model_size(HeavyUnet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa993f5-0785-4dac-b9ab-2d9c2fb3c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light weight Unet\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.inc = DoubleConv(1, 32)         \n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(32, 64)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(64, 128)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(128, 256)\n",
    "        )\n",
    "        self.down4 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(256, 512)\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.conv_up1 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv_up2 = DoubleConv(256, 128)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv_up3 = DoubleConv(128, 64)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.conv_up4 = DoubleConv(64, 32)\n",
    "\n",
    "        self.outc = nn.Conv2d(32, 1, kernel_size=1)\n",
    "\n",
    "    #######DO NOT CHANGE THIS PART########\n",
    "    def init(self, path=\"model.pth\"):\n",
    "        self.load_state_dict(torch.load(path, weights_only=True))\n",
    "    ######################################\n",
    "    def save(self, path: str):\n",
    "        torch.save(copy.deepcopy(self.state_dict()), path)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self.inc(x)     \n",
    "        x2 = self.down1(x1)    \n",
    "        x3 = self.down2(x2)    \n",
    "        x4 = self.down3(x3)    \n",
    "        x5 = self.down4(x4)   \n",
    "\n",
    "        x = self.up1(x5)       \n",
    "        x = torch.cat([x, x4], dim=1) \n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.up2(x)       \n",
    "        x = torch.cat([x, x3], dim=1) \n",
    "        x = self.conv_up2(x) \n",
    "\n",
    "        x = self.up3(x)        \n",
    "        x = torch.cat([x, x2], dim=1)  \n",
    "        x = self.conv_up3(x)  \n",
    "\n",
    "        x = self.up4(x)        \n",
    "        x = torch.cat([x, x1], dim=1)  \n",
    "        x = self.conv_up4(x)  \n",
    "\n",
    "        mask = self.outc(x)   \n",
    "        return mask\n",
    "\n",
    "get_model_size(Model())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f732869-a0d6-444f-b43e-68c9b53dc360",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ca785-0538-4626-9bd7-b99c1c2684e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODELS_DIR = \"./best_models\"\n",
    "STABLE_MODELS_DIR = \"./stable_models\"\n",
    "PLOTS_DIR = \"./plots\"\n",
    "\n",
    "! rm -rf \"./best_models\"\n",
    "! rm -rf \"./stable_models\"\n",
    "! rm -rf \"./plots\"\n",
    "\n",
    "os.makedirs(BEST_MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(STABLE_MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f1dec-5459-489d-9278-3400bc52f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model()\n",
    "\n",
    "(train_losses,\n",
    "train_dice_scores,\n",
    "val_losses,\n",
    "val_dice_scores,\n",
    "best_model_path,\n",
    "best_stable_model_path,\n",
    "best_model_test_loss,\n",
    "best_model_test_dice_score,\n",
    "stable_model_test_loss,\n",
    "stable_model_test_dice_score) = train(model = model, epochs = 100,\n",
    "                                      train_dataset = train_dataset, val_dataset = val_dataset, test_dataset = test_dataset,\n",
    "                                      stable_epochs_count = 5,\n",
    "                                      stable_dice_score_distance = 0.01,\n",
    "                                      best_models_dir = BEST_MODELS_DIR,\n",
    "                                      stable_models_dir = STABLE_MODELS_DIR)\n",
    "\n",
    "plot_metrics(train_losses, val_losses, 'Loss')\n",
    "plot_metrics(train_dice_scores, val_dice_scores, 'Scores')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e0ce3-e8a0-464d-b247-eb9d72b01f6c",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613697c2-85b1-4092-98f3-601a235a94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_conf = torch.load('./best_models/dice_0.4801_epoch_22_64d.pth')\n",
    "model = Model()\n",
    "model.load_state_dict(stable_conf)\n",
    "model.save('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38307c98-5176-42b9-b6f6-3cf4d0461979",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e50f1a2-5f60-4b36-8ade-98a0bef7b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('submission.zip', 'w') as zipf:\n",
    "    zipf.write('model.pth')\n",
    "    zipf.write('model.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
