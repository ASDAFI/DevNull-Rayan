{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97da6e3-dd4e-4349-8f5f-0a833deac0c3",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac57c2a-9873-4ba9-a51c-a096774a7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "\n",
    "! rm -rf logs\n",
    "\n",
    "log_dir = 'logs'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "LOGGER = logging.getLogger('notebook')\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "\n",
    "log_file_path = os.path.join(log_dir, 'run.log')\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "LOGGER.addHandler(file_handler)\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(formatter)\n",
    "LOGGER.addHandler(console_handler)\n",
    "\n",
    "logging_redirect_tqdm()\n",
    "\n",
    "LOGGER.debug(\"This is a debug message\")\n",
    "LOGGER.info(\"This is an info message\")\n",
    "LOGGER.warning(\"This is a warning message\")\n",
    "LOGGER.error(\"This is an error message\")\n",
    "LOGGER.critical(\"This is a critical message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1854d-c025-47f8-a424-d345de039901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def timeit(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        LOGGER.info(f\"Function '{func.__name__}' executed in {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da137960-001c-46e5-878a-1fdaa7b01e21",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a3862-0c69-4e04-9802-d75f24021013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "dataset_id = \"RayanAi/Noisy_birds\"\n",
    "local_dataset_dir = \"./Noisy_birds\"\n",
    "\n",
    "os.makedirs(local_dataset_dir, exist_ok=True)\n",
    "\n",
    "with open(os.devnull, 'w') as fnull:\n",
    "    original_stdout = sys.stdout\n",
    "    try:\n",
    "        sys.stdout = fnull\n",
    "        snapshot_download(repo_id=dataset_id, local_dir=local_dataset_dir, repo_type=\"dataset\")\n",
    "    finally:\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "LOGGER.info(\"Dataset downloaded completely.\")\n",
    "\n",
    "total_size = 0\n",
    "for dirpath, dirnames, filenames in os.walk(local_dataset_dir):\n",
    "    for f in filenames:\n",
    "        fp = os.path.join(dirpath, f)\n",
    "        total_size += os.path.getsize(fp)\n",
    "\n",
    "LOGGER.info(f\"Total size of downloaded files: {total_size / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "dataset_abs_path = os.path.abspath(local_dataset_dir)\n",
    "LOGGER.info(f\"Dataset has been saved at: [{dataset_abs_path}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf2151-ff61-406d-96c5-211a2b39d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qo ./Noisy_birds/Noisy_birds.zip -d ./Noisy_birds/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de76282a-176f-4491-9016-5a524396a965",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0c2473-fe62-46f5-89cb-5c40006a6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_image(image_path: str) -> Image.Image:\n",
    "    image = Image.open(image_path)\n",
    "    return image\n",
    "\n",
    "def get_label_from_path(image_path: str) -> str:\n",
    "    return os.path.basename(os.path.dirname(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a817e1-4276-407b-b220-46d7cecc40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BirdsDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.loaded_data: List[torch.Tensor] = []\n",
    "        self.X: List[torch.Tensor] = []\n",
    "        self.y: List[str] = []\n",
    "\n",
    "    @timeit\n",
    "    def load(self, data: List[Tuple[str, str]]):\n",
    "        for image_path, label in data:\n",
    "            image = load_image(image_path)\n",
    "            self.loaded_data.append((image, label))\n",
    "\n",
    "    @timeit\n",
    "    def augment(self, generation_per_label: dict, augmentation: transforms.Compose):\n",
    "        LOGGER.info(\"Augmenting data ...\")\n",
    "        for image, label in tqdm(self.loaded_data.copy()):\n",
    "            for _ in range(generation_per_label[label]):\n",
    "                augmented_image = augmentation(image)\n",
    "                self.loaded_data.append((augmented_image, label))\n",
    "        random.seed(68)\n",
    "        random.shuffle(self.loaded_data)\n",
    "\n",
    "    @timeit\n",
    "    def transform(self, transformation: transforms.Compose):\n",
    "        for image, label in self.loaded_data:\n",
    "            self.X.append(transformation(image))\n",
    "            self.y.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940ce87-78d6-4db8-9e8c-4fc9df6fc90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_TO_CLASS = [\"budgie\",\"canary\",\"duckling\",\"rubber duck\"]\n",
    "CLASS_TO_IDX = {key: IDX_TO_CLASS.index(key) for key in IDX_TO_CLASS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a929ab-b4db-4c2a-8457-cb15e44bb109",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793e8e4-32db-4b16-ab83-f380edfc8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class EfficientNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EfficientNetClassifier, self).__init__()\n",
    "        self.model = models.efficientnet_b0(weights='EfficientNet_B0_Weights.IMAGENET1K_V1')\n",
    "\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def save(self, path: str):\n",
    "        torch.save(copy.deepcopy(self.state_dict()), path)\n",
    "\n",
    "    def init(self, path: str = \"model.pth\"):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "e_net_classifier = EfficientNetClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21ca18-5171-4537-ac4d-f167dc874816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        self.model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n",
    "\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def save(self, path: str):\n",
    "        torch.save(copy.deepcopy(self.state_dict()), path)\n",
    "\n",
    "    def init(self, path: str = \"model.pth\"):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "res_net_18_classifier = ResNet18Classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed8837-f448-42ac-b050-62c0ca731ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LOGGER.info(f'Device is {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3e884-15ab-4f94-8610-003c8347d771",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ae4e4-15e5-4a98-9675-a4baa31e0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_string(length=8, use_digits=True, use_lowercase=True, use_uppercase=True, use_special=False):\n",
    "    char_pool = ''\n",
    "    if use_digits:\n",
    "        char_pool += string.digits\n",
    "    if use_lowercase:\n",
    "        char_pool += string.ascii_lowercase\n",
    "    if use_uppercase:\n",
    "        char_pool += string.ascii_uppercase\n",
    "    if use_special:\n",
    "        char_pool += string.punctuation\n",
    "\n",
    "    if not char_pool:\n",
    "        raise ValueError(\"At least one character type must be enabled.\")\n",
    "\n",
    "    return ''.join(random.choice(char_pool) for _ in range(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43ccf1-bfb8-4f25-9367-910a806547de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "@timeit\n",
    "def train_epoch(model: torch.nn.Module, train_loader: DataLoader, optimizer, criterion) -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_targets = []\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(DEVICE), torch.tensor([CLASS_TO_IDX[label] for label in labels], dtype=torch.long).to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_preds.extend(predicted.cpu().numpy())\n",
    "        train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_accuracy = accuracy_score(train_targets, train_preds)\n",
    "    epoch_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "\n",
    "    return train_accuracy, epoch_train_loss\n",
    "\n",
    "@timeit\n",
    "def evaluate_epoch(model: torch.nn.Module, val_loader: DataLoader, criterion) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(val_loader):\n",
    "            inputs, labels = inputs.to(DEVICE), torch.tensor([CLASS_TO_IDX[label] for label in labels], dtype=torch.long).to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_preds.extend(predicted.cpu().numpy())\n",
    "            val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_targets, val_preds)\n",
    "    epoch_val_loss = total_val_loss / len(val_loader.dataset)\n",
    "\n",
    "    return val_accuracy, epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255b38a-0619-4a2b-88e8-7dbce3eeddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def train_with_validation(model: torch.nn.Module, train_dataset: Dataset, val_dataset: Dataset,\n",
    "                          epochs: int, stability_epochs: int, max_stability_distance: float,\n",
    "                         best_models_dir: str, stable_models_dir: str):\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "    best_stable_accuracy = 0\n",
    "\n",
    "    best_model_path = \"\"\n",
    "    best_stable_model_path = \"\"\n",
    "\n",
    "    models_history_in_memory = []\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_accuracy, epoch_train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        val_accuracy, epoch_val_loss = evaluate_epoch(model, val_loader, criterion)\n",
    "\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "\n",
    "        models_history_in_memory.append(copy.deepcopy(model))\n",
    "        if len(models_history_in_memory) > 50:\n",
    "            del models_history_in_memory[0]\n",
    "            models_history_in_memory.insert(0, None)\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            model_path = os.path.join(best_models_dir,\n",
    "                                      f'acc_{round(val_accuracy, 4)}_with_data_epoch_{epoch}_{generate_random_string(3)}.pth')\n",
    "            model.save(model_path)\n",
    "            best_model_path = model_path\n",
    "\n",
    "            LOGGER.info(f'model {model_path} has been saved.')\n",
    "\n",
    "\n",
    "        if epoch >= 50 and all([abs(err1 - err2) <= max_stability_distance for err1 in val_accuracies[-stability_epochs:]\n",
    "                            for err2 in val_accuracies[-stability_epochs:]]):\n",
    "            idx = epoch - stability_epochs // 2\n",
    "            if val_accuracies[idx] >= best_stable_accuracy:\n",
    "                best_stable_accuracy = val_accuracies[idx]\n",
    "\n",
    "                model_path = os.path.join(stable_models_dir,\n",
    "                                          f'acc_{round(val_accuracies[idx], 4)}_epoch_{idx + 1}_{generate_random_string(3)}.pth')\n",
    "                models_history_in_memory[idx].save(model_path)\n",
    "                best_stable_model_path = model_path\n",
    "\n",
    "                LOGGER.info(f'model {model_path} has been saved.')\n",
    "\n",
    "\n",
    "        LOGGER.info(f'\\nEpoch {epoch+1}/{epochs}, '\n",
    "              f'Training Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}, '\n",
    "              f'Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n')\n",
    "\n",
    "    return (\n",
    "        best_model_path,\n",
    "        best_stable_model_path,\n",
    "        train_losses,\n",
    "        val_losses,\n",
    "        train_accuracies,\n",
    "        val_accuracies\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c73d84-9c54-48f3-a9ee-19e2a8752647",
   "metadata": {},
   "source": [
    "# Plot utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1193721-4d7d-4681-845c-d909fe34c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(train_metric, val_metric, save_path, metric_name=\"Loss\", color_train='b', color_val='r'):\n",
    "    epochs = range(1, len(train_metric) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_metric, color=color_train, label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, val_metric, color=color_val, label=f'Validation {metric_name}')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'Training and Validation {metric_name} Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ba153b-b8fa-45fe-8318-fe719b319a66",
   "metadata": {},
   "source": [
    "# Gradual Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c33aaf-00f4-4e73-8fb0-be026cbeaed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_learned_images(other_images: List[Tuple[str, str]],\n",
    "                       model: torch.nn.Module,\n",
    "                       confidence_threshold: float,\n",
    "                       confidence_distance_threshold: float,\n",
    "                       transformation: transforms.Compose) -> List[Tuple[str, str]]:\n",
    "    model.eval()\n",
    "    model = model.to(DEVICE)\n",
    "    learned_images = []\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    for image_path, real_label in other_images:\n",
    "        image = load_image(image_path)\n",
    "        image = transformation(image)\n",
    "        image = image.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            probs = softmax(outputs)\n",
    "\n",
    "            top2_probs, top2_preds = torch.topk(probs, 2, dim=1)\n",
    "            top2_probs = top2_probs.squeeze() \n",
    "\n",
    "            most_confident = top2_probs[0].item()\n",
    "            second_most_confident = top2_probs[1].item()\n",
    "            pred_class_idx = top2_preds[0, 0].item()  \n",
    "            pred_class_name = IDX_TO_CLASS[pred_class_idx]\n",
    "\n",
    "            if most_confident >= confidence_threshold and \\\n",
    "                (most_confident - second_most_confident) > confidence_distance_threshold:\n",
    "                learned_images.append((image_path, pred_class_name))\n",
    "\n",
    "    return learned_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca46486-76b7-499d-b3e4-0948bfca019c",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7500dc3-5138-41b9-bdae-db0e8bc50d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_images_path = [(path, get_label_from_path(path)) for path in glob.glob(os.path.join(local_dataset_dir, '*/*.jpg'))]\n",
    "\n",
    "images_path = [data for data in all_images_path if data[1] != 'unlabeled']\n",
    "unlabeled_images_path = [data for data in all_images_path if data[1] == 'unlabeled']\n",
    "unlabeled_images_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3102ee-d6fb-4e51-9948-94c2be547f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TRANSFORMATION = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "TRAIN_TRANSFORMATION = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29361580-581f-49cb-b218-647feec14c1e",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2778395-59da-4f95-a3c7-1d190b65af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION_TRANSFORMATION = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=30),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3), #saturation=0.3, hue=0.2),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 1), sigma=(0.001, 5)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410309d6-a60f-49d7-b479-b22ffde42c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "AMOUNT_PER_LABEL = 2000\n",
    "\n",
    "def get_augment_per_label(data: List[Tuple[str, str]]) -> Dict[str, int] :\n",
    "    labels = list(set(dt[0] for dt in data))\n",
    "    generation_per_label = defaultdict(lambda: 0)\n",
    "    for _, label in data:\n",
    "        generation_per_label[label] += 1\n",
    "\n",
    "    for label in generation_per_label.keys():\n",
    "        generation_per_label[label] = AMOUNT_PER_LABEL // generation_per_label[label] + 1\n",
    "    return generation_per_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ebe73-141c-461c-aed6-0fc9f1691112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.shuffle(images_path)\n",
    "\n",
    "known_images_path = images_path[:120].copy()\n",
    "unknown_images_path = unlabeled_images_path.copy()#\n",
    "validation_images_path = images_path[120:].copy()\n",
    "\n",
    "\n",
    "validation_dataset = BirdsDataset()\n",
    "validation_dataset.load(validation_images_path)\n",
    "validation_dataset.transform(TEST_TRANSFORMATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5d14b0-784a-4f26-b7f6-642b58b736a9",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5070cc-6612-4933-b765-7ed59341ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODELS_DIR = \"./best_models\"\n",
    "STABLE_MODELS_DIR = \"./stable_models\"\n",
    "PLOTS_DIR = \"./plots\"\n",
    "\n",
    "! rm -rf \"./best_models\"\n",
    "! rm -rf \"./stable_models\"\n",
    "! rm -rf \"./plots\"\n",
    "\n",
    "os.makedirs(BEST_MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(STABLE_MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ab9a5-b875-4315-ad0b-155950e95b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "\n",
    "while True:\n",
    "    known_dataset = BirdsDataset()\n",
    "    known_dataset.load(known_images_path)\n",
    "    aug_amount = get_augment_per_label(known_images_path)\n",
    "    known_dataset.augment(aug_amount, AUGMENTATION_TRANSFORMATION)\n",
    "    known_dataset.transform(TRAIN_TRANSFORMATION)\n",
    "\n",
    "    model = EfficientNetClassifier()\n",
    "\n",
    "    best_model_path, stable_model_path,  train_losses, val_losses, train_accuracies, val_accuracies = train_with_validation \\\n",
    "                        (model=model, train_dataset=known_dataset, val_dataset = validation_dataset,\n",
    "                          epochs=EPOCHS, stability_epochs = 10, max_stability_distance = 0.1,\n",
    "                         best_models_dir = BEST_MODELS_DIR, stable_models_dir = STABLE_MODELS_DIR)\n",
    "\n",
    "    plot_metrics(train_losses, val_losses,\n",
    "                 os.path.join(PLOTS_DIR, f'loss_with_{len(known_dataset)}_data.png'), 'Loss')\n",
    "    plot_metrics(train_accuracies, val_accuracies,\n",
    "                 os.path.join(PLOTS_DIR, f'accuracy_with_{len(known_dataset)}_data.png'), 'Accuracy')\n",
    "\n",
    "    stable_model = EfficientNetClassifier()\n",
    "    best_model = EfficientNetClassifier()\n",
    "\n",
    "    stable_model.init(stable_model_path)\n",
    "    best_model.init(best_model_path)\n",
    "\n",
    "\n",
    "    conf_threshold = 0.47\n",
    "    model = stable_model\n",
    "    \n",
    "    learned_images = get_learned_images(other_images = unknown_images_path,\n",
    "                           model=best_model,\n",
    "                           confidence_threshold = conf_threshold,\n",
    "                           confidence_distance_threshold = 0.2,\n",
    "                           transformation = TEST_TRANSFORMATION)\n",
    "    \n",
    "    LOGGER.info(f'{len(learned_images)} has been found successfuly!')\n",
    "\n",
    "    if not learned_images:\n",
    "        break\n",
    "\n",
    "    known_images_path.extend(learned_images)\n",
    "    for image_path, _ in learned_images:\n",
    "        unknown_images_path.remove((image_path, get_label_from_path(image_path)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f465e9f-8b6a-4e85-bf42-07c863e3c5f3",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e5a43-4b96-4f5f-92e1-c2c7b7501c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stable_model.save('model.pth')\n",
    "stable_conf = torch.load('./best_models/acc_1.0_with_data_epoch_7_to4.pth')\n",
    "model = EfficientNetClassifier()\n",
    "model.load_state_dict(stable_conf)\n",
    "model.save('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f41bd2-e4e5-4baa-917a-f1dec790ef01",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a6d3b9-d0b7-4669-8309-c46410577c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('submission.zip', 'w') as zipf:\n",
    "    zipf.write('model.pth')\n",
    "    zipf.write('model.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec845540-6030-41cd-88fe-290ba357d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
