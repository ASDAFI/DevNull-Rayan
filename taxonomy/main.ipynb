{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c061d5-0db6-4598-933d-2d3098d80f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Iterator\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eadafe5-0cfe-44c7-9a64-8556f5ceae38",
   "metadata": {},
   "source": [
    "# Download and Extract dataset \n",
    "11GB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef2bef-ab7c-4151-9417-7999dd4b137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(repo_id='RayanAi/inat_train_modified', filename=\"inat_train_modified.tar.gz\", repo_type=\"dataset\", local_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f61f4a-936f-4615-aac7-ad66b01a1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xfz inat_train_modified.tar.gz -C ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e7c92-0696-496b-9ba8-b6720683b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self._count = 0\n",
    "        self.children = {}\n",
    "        self._entities = []\n",
    "\n",
    "    def add_to_node(self, path, entity, level=0):\n",
    "        if level >= len(path):\n",
    "            self._entities.append(entity)\n",
    "            return\n",
    "        part = path[level]\n",
    "        if part not in self.children:\n",
    "            self.children[part] = Node(path[:level+1])\n",
    "        self.children[part].add_to_node(path, entity, level=level+1)\n",
    "        self._count += 1\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return len(self._entities) > 0\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        if self.is_leaf:\n",
    "            return len(self._entities)\n",
    "        else:\n",
    "            return self._count\n",
    "\n",
    "    @property\n",
    "    def entities(self):\n",
    "        if self.is_leaf:\n",
    "            return list((entity, self.name) for entity in self._entities)\n",
    "        else:\n",
    "            child_entities = []\n",
    "            for child in self.children.values():\n",
    "                child_entities.extend(child.entities)\n",
    "        return child_entities\n",
    "\n",
    "    def level_iterator(self, level=None):\n",
    "        \"\"\"\n",
    "        iterates a certain depth in a tree and returns the nodes\n",
    "        \"\"\"\n",
    "        if level == 0:\n",
    "            yield self\n",
    "        elif level == None and self.is_leaf:\n",
    "            yield self\n",
    "        elif self.is_leaf and level != 0:\n",
    "            raise Exception(\"Incorrect level is specified in tree.\")\n",
    "        else:\n",
    "            if level is not None:\n",
    "                level -= 1\n",
    "            for child in self.children.values():\n",
    "                for v in child.level_iterator(level):\n",
    "                    yield v\n",
    "\n",
    "\n",
    "    def print_node(self, level=0, max_level=None):\n",
    "        leaves = 1\n",
    "        print(' ' * (level * 4) + f\"{self.name[-1]} ({self.count})\")\n",
    "        for node in self.children.values():\n",
    "            if max_level is None or level < max_level:\n",
    "                leaves += node.print_node(level + 1, max_level=max_level)\n",
    "        return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34e931-71cf-4f7d-a3fa-42536dc642cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiererchicalDataset(Dataset):\n",
    "    def __init__(self, dataset_path, level=None):\n",
    "        self.tree = Node(\"Dataset\") # keeps the group information of self.data in a tree (per index).\n",
    "        self.level = level\n",
    "        if level is None:\n",
    "            self.level = 7  # Hardcoded\n",
    "        self.classes = set()\n",
    "        data = []\n",
    "        index = 0\n",
    "        for group_name in sorted(os.listdir(dataset_path)):\n",
    "            if not os.path.isdir(os.path.join(dataset_path, group_name)):\n",
    "                continue\n",
    "            for image_name in sorted(os.listdir(os.path.join(dataset_path, group_name))):\n",
    "                group = tuple(group_name.split(\"_\")[1:])\n",
    "                image_path = os.path.join(dataset_path, group_name, image_name)\n",
    "                data.append({\n",
    "                        \"image_path\": image_path,\n",
    "                        \"group\": group,\n",
    "                    }\n",
    "                )\n",
    "                self.tree.add_to_node(group, index)\n",
    "                index += 1\n",
    "                self.classes.add(group[:self.level])\n",
    "        self.data = data\n",
    "        self.classes = {group: index for (index, group) in enumerate(sorted(list(self.classes)))}\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.RandomCrop(224, padding=4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4556, 0.4714, 0.3700), (0.2370, 0.2318, 0.2431))\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.data[idx][\"image_path\"])\n",
    "        target = self.classes[self.data[idx][\"group\"][:self.level]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def get_group_iterator(self, level=None) -> Iterator[Node]:\n",
    "        for group in self.tree.level_iterator(level):\n",
    "            yield group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a9563-e4b9-43c4-9989-365b13e8c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = HiererchicalDataset('train', level=2)\n",
    "print(\"Dataset Length:\", f\"{len(test)}\")\n",
    "test.tree.print_node(max_level=2)\n",
    "print(test.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f94c9d-8d17-4ae8-a8e9-4fea3ec19154",
   "metadata": {},
   "source": [
    "# Augment and Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629763bc-d6f5-48ec-aee5-8372792e327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "AUGMENTATION_TRANSFORMATION = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 1), sigma=(0.001, 5)),\n",
    "])\n",
    "\n",
    "class AugmentativeDataset(Dataset):\n",
    "    def __init__(self, original_dataset, output_dir, target_size=10000):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        class_counts = defaultdict(int)\n",
    "        for item in original_dataset.data:\n",
    "            group = item[\"group\"][:original_dataset.level]\n",
    "            class_counts[group] += 1\n",
    "\n",
    "        print(\"Original class distribution:\")\n",
    "        for group, count in class_counts.items():\n",
    "            print(f\"Class {group}: {count} samples\")\n",
    "\n",
    "        self.balanced_data = []\n",
    "        for group, count in class_counts.items():\n",
    "            group_data = [item for item in original_dataset.data if item[\"group\"][:original_dataset.level] == group]\n",
    "            group_dir = self.output_dir / \"_\".join(group)\n",
    "            group_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if count < target_size:\n",
    "                required_samples = target_size - count\n",
    "                print(f\"Generating {required_samples} samples for class {group}\")\n",
    "\n",
    "                for _ in tqdm(range(required_samples)):\n",
    "                    sample = random.choice(group_data)\n",
    "                    image = Image.open(sample[\"image_path\"])\n",
    "                    augmented_image = AUGMENTATION_TRANSFORMATION(image)\n",
    "\n",
    "                    filename = f\"{group}_{len(self.balanced_data)}.png\"\n",
    "                    filepath = group_dir / filename\n",
    "                    augmented_image.save(filepath)\n",
    "                    \n",
    "                    self.balanced_data.append({\n",
    "                        \"image_path\": filepath,\n",
    "                        \"group\": sample[\"group\"]\n",
    "                    })\n",
    "\n",
    "            elif count > target_size:\n",
    "                print(f\"Sampling down {count - target_size} samples for class {group}\")\n",
    "                sampled_data = random.sample(group_data, target_size)\n",
    "                self.balanced_data.extend(sampled_data)\n",
    "            else:\n",
    "                self.balanced_data.extend(group_data)\n",
    "\n",
    "        print(\"Data balancing complete.\")\n",
    "        print(f\"Total samples after balancing: {len(self.balanced_data)}\")\n",
    "\n",
    "        self.transform = original_dataset.transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.balanced_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.balanced_data[idx][\"image_path\"])\n",
    "        target = self.original_dataset.classes[self.balanced_data[idx][\"group\"][:self.original_dataset.level]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498c73b-f941-4e47-921c-0039c4f9bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf balanced_train\n",
    "dataset_path = 'train'\n",
    "balanced_output_dir = 'balanced_train'\n",
    "train_dataset = HiererchicalDataset(dataset_path=dataset_path, level=2)\n",
    "balanced_dataset =  AugmentativeDataset(train_dataset, balanced_output_dir)\n",
    "\n",
    "print(\"Balanced Dataset Length:\", len(balanced_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc856c-b143-4434-b384-b7ca9cc121b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, level=None):\n",
    "        self.tree = Node(\"Dataset\")\n",
    "        self.level = level\n",
    "        if level is None:\n",
    "            self.level = 7\n",
    "        self.classes = set()\n",
    "        data = []\n",
    "        index = 0\n",
    "        dataset_path = 'balanced_train'\n",
    "        for group_name in sorted(os.listdir(dataset_path)):\n",
    "            if not os.path.isdir(os.path.join(dataset_path, group_name)):\n",
    "                continue\n",
    "\n",
    "            files = os.listdir(os.path.join(dataset_path, group_name))\n",
    "            is_balanced = 1\n",
    "            dst_path = dataset_path\n",
    "            if len(files) == 0:\n",
    "                files = glob.glob(os.path.join('train', f'*_{group_name}_*/*.jpg'))\n",
    "                is_balanced = 0\n",
    "                dst_path = 'train'\n",
    "                if len(files) > 10000:\n",
    "                    files = random.sample(files, 10000)\n",
    "                \n",
    "            for image_name in sorted(files):\n",
    "                if is_balanced == 0:\n",
    "                    group_name = os.path.dirname(image_name).split('/')[-1]\n",
    "                    group = tuple(group_name.split(\"_\")[1:])\n",
    "                    image_path = image_name\n",
    "                else:\n",
    "                    group = tuple(group_name.split(\"_\")[:])\n",
    "                    image_path = os.path.join(dst_path, group_name, image_name)\n",
    "\n",
    "                \n",
    "                \n",
    "                data.append({\n",
    "                        \"image_path\": image_path,\n",
    "                        \"group\": group,\n",
    "                    }\n",
    "                )\n",
    "                self.tree.add_to_node(group, index)\n",
    "                index += 1\n",
    "                self.classes.add(group[:self.level])\n",
    "        self.data = data\n",
    "        self.classes = {group: index for (index, group) in enumerate(sorted(list(self.classes)))}\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.RandomCrop(224, padding=4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4556, 0.4714, 0.3700), (0.2370, 0.2318, 0.2431))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.data[idx][\"image_path\"])\n",
    "        target = self.classes[self.data[idx][\"group\"][:self.level]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def get_group_iterator(self, level=None) -> Iterator[Node]:\n",
    "        for group in self.tree.level_iterator(level):\n",
    "            yield group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffc391-52aa-41a6-9b1e-b51802bf45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BalancedDataset(level=2)\n",
    "print(\"Dataset Length:\", f\"{len(train_dataset)}\")\n",
    "train_dataset.tree.print_node(max_level=2)\n",
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe3f7f6-795b-4d7a-b3ca-2e9a7d230fc6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70751397-d281-41c2-aaaa-1930d7918347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(repo_id='RayanAi/resnet50-pretrained-inat', filename=\"resnet50.pth\", repo_type=\"model\", local_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeca1ea-6d9b-421c-af4d-9d6d0c642696",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes.keys()))\n",
    "\n",
    "model.load_state_dict(torch.load(\"resnet50.pth\"))\n",
    "\n",
    "\n",
    "################### OPTIONAL #########################\n",
    "model.requires_grad_(True)\n",
    "model.fc.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f81958f-62f9-4fd4-856e-672d77d66b6e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11a5a9-ef87-4f35-bd0f-bbd757fa2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf checkpoints\n",
    "!mkdir -p checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f95a3-634b-4034-9223-dd34d448a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fccac-1201-4dd0-84e7-bbaaee86bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"simple-training\"\n",
    "print(\"Experiment {}\".format(experiment_name))\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "batch_size = 256\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "\n",
    "\n",
    "print(f\"Dataset Length: {len(train_dataset)}, Batch size: {batch_size}, LR: {learning_rate}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=learning_rate)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Update tqdm progress bar description\n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\", accuracy=f\"{100. * correct / total:.2f}%\")\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "    print(f\"Epoch {epoch} | Training Loss: {epoch_loss:.4f} | Training Accuracy: {epoch_acc:.4f} | Time: {epoch_time:.2f}s\")\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "best_acc = 0.0\n",
    "print(f\"Starting training for {num_epochs} epochs.\")\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device, epoch, num_epochs)\n",
    "\n",
    "\n",
    "    # Save the latest model\n",
    "    latest_checkpoint_path = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "    }, latest_checkpoint_path)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}] Summary: \"\n",
    "                 f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # Save the best model based on test accuracy\n",
    "    # if train_acc > best_acc:\n",
    "    #     best_acc = train_acc\n",
    "    #     best_checkpoint_path = os.path.join(checkpoint_dir, 'best_checkpoint.pth')\n",
    "    #     save_checkpoint({\n",
    "    #         'epoch': epoch,\n",
    "    #         'model_state_dict': model.state_dict(),\n",
    "    #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #         'train_loss': train_loss,\n",
    "    #         'train_acc': train_acc,\n",
    "    #     }, best_checkpoint_path)\n",
    "    #     print(f\"New best model saved with accuracy: {best_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1a2dd-d35f-47e2-9d94-b74f75e923d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "torch.save(model.state_dict(), 'resnet.pth')\n",
    "with zipfile.ZipFile('submission.zip', 'w') as zipf:\n",
    "    zipf.write('resnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
